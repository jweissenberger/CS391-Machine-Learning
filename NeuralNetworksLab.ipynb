{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4:  Neural Network Lab\n",
    "## Jack Weissenberger\n",
    "### Part 1: Compare number of hidden layers to the accuracy of the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first few cells, we are loading the mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    " \n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path, \n",
    "                               '%s-labels-idx1-ubyte' % kind)\n",
    "    images_path = os.path.join(path, \n",
    "                               '%s-images-idx3-ubyte' % kind)\n",
    "        \n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II', \n",
    "                                 lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath, \n",
    "                             dtype=np.uint8)\n",
    "\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", \n",
    "                                               imgpath.read(16))\n",
    "        images = np.fromfile(imgpath, \n",
    "                             dtype=np.uint8).reshape(len(labels), 784)\n",
    "        images = ((images / 255.) - .5) * 2\n",
    " \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzips mnist\n",
    "\n",
    "import sys\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "if (sys.version_info > (3, 0)):\n",
    "    writemode = 'wb'\n",
    "else:\n",
    "    writemode = 'w'\n",
    "\n",
    "zipped_mnist = [f for f in os.listdir('./') if f.endswith('ubyte.gz')]\n",
    "for z in zipped_mnist:\n",
    "    with gzip.GzipFile(z, mode='rb') as decompressed, open(z[:-3], writemode) as outfile:\n",
    "        outfile.write(decompressed.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 60000, columns: 784\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_mnist('', kind='train')\n",
    "print('Rows: %d, columns: %d' % (X_train.shape[0], X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 10000, columns: 784\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = load_mnist('', kind='t10k')\n",
    "print('Rows: %d, columns: %d' % (X_test.shape[0], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('mnist_scaled.npz', \n",
    "                    X_train=X_train,\n",
    "                    y_train=y_train,\n",
    "                    X_test=X_test,\n",
    "                    y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test', 'y_train', 'X_test', 'X_train']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = np.load('mnist_scaled.npz')\n",
    "mnist.files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are assigning the the split data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = [mnist[f] for f in ['X_train', 'y_train', \n",
    "                                    'X_test', 'y_test']]\n",
    "\n",
    "del mnist\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we define the methods we will need for the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetMLP(object):\n",
    "    \"\"\" Feedforward neural network / Multi-layer perceptron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    n_hidden : int (default: 30)\n",
    "        Number of hidden units.\n",
    "    l2 : float (default: 0.)\n",
    "        Lambda value for L2-regularization.\n",
    "        No regularization if l2=0. (default)\n",
    "    epochs : int (default: 100)\n",
    "        Number of passes over the training set.\n",
    "    eta : float (default: 0.001)\n",
    "        Learning rate.\n",
    "    shuffle : bool (default: True)\n",
    "        Shuffles training data every epoch if True to prevent circles.\n",
    "    minibatch_size : int (default: 1)\n",
    "        Number of training samples per minibatch.\n",
    "    seed : int (default: None)\n",
    "        Random seed for initalizing weights and shuffling.\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    eval_ : dict\n",
    "      Dictionary collecting the cost, training accuracy,\n",
    "      and validation accuracy for each epoch during training.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, n_hidden=30,\n",
    "                 l2=0., epochs=100, eta=0.001,\n",
    "                 shuffle=True, minibatch_size=1, seed=None):\n",
    "\n",
    "        self.random = np.random.RandomState(seed)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.l2 = l2\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatch_size = minibatch_size\n",
    "\n",
    "    def _onehot(self, y, n_classes):\n",
    "        \"\"\"Encode labels into one-hot representation\n",
    "\n",
    "        Parameters\n",
    "        ------------\n",
    "        y : array, shape = [n_samples]\n",
    "            Target values.\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        onehot : array, shape = (n_samples, n_labels)\n",
    "\n",
    "        \"\"\"\n",
    "        onehot = np.zeros((n_classes, y.shape[0]))\n",
    "        for idx, val in enumerate(y.astype(int)):\n",
    "            onehot[val, idx] = 1.\n",
    "        return onehot.T\n",
    "\n",
    "    def _sigmoid(self, z):\n",
    "        \"\"\"Compute logistic function (sigmoid)\"\"\"\n",
    "        return 1. / (1. + np.exp(-np.clip(z, -250, 250)))\n",
    "\n",
    "    def _forward(self, X):\n",
    "        \"\"\"Compute forward propagation step\"\"\"\n",
    "\n",
    "        # step 1: net input of hidden layer\n",
    "        # [n_samples, n_features] dot [n_features, n_hidden]\n",
    "        # -> [n_samples, n_hidden]\n",
    "        z_h = np.dot(X, self.w_h) + self.b_h\n",
    "\n",
    "        # step 2: activation of hidden layer\n",
    "        a_h = self._sigmoid(z_h)\n",
    "\n",
    "        # step 3: net input of output layer\n",
    "        # [n_samples, n_hidden] dot [n_hidden, n_classlabels]\n",
    "        # -> [n_samples, n_classlabels]\n",
    "\n",
    "        z_out = np.dot(a_h, self.w_out) + self.b_out\n",
    "\n",
    "        # step 4: activation output layer\n",
    "        a_out = self._sigmoid(z_out)\n",
    "\n",
    "        return z_h, a_h, z_out, a_out\n",
    "\n",
    "    def _compute_cost(self, y_enc, output):\n",
    "        \"\"\"Compute cost function.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_enc : array, shape = (n_samples, n_labels)\n",
    "            one-hot encoded class labels.\n",
    "        output : array, shape = [n_samples, n_output_units]\n",
    "            Activation of the output layer (forward propagation)\n",
    "\n",
    "        Returns\n",
    "        ---------\n",
    "        cost : float\n",
    "            Regularized cost\n",
    "\n",
    "        \"\"\"\n",
    "        L2_term = (self.l2 *\n",
    "                   (np.sum(self.w_h ** 2.) +\n",
    "                    np.sum(self.w_out ** 2.)))\n",
    "\n",
    "        term1 = -y_enc * (np.log(output))\n",
    "        term2 = (1. - y_enc) * np.log(1. - output)\n",
    "        cost = np.sum(term1 - term2) + L2_term\n",
    "        return cost\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        X : array, shape = [n_samples, n_features]\n",
    "            Input layer with original features.\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        y_pred : array, shape = [n_samples]\n",
    "            Predicted class labels.\n",
    "\n",
    "        \"\"\"\n",
    "        z_h, a_h, z_out, a_out = self._forward(X)\n",
    "        y_pred = np.argmax(z_out, axis=1)\n",
    "        return y_pred\n",
    "\n",
    "    def fit(self, X_train, y_train, X_valid, y_valid):\n",
    "        \"\"\" Learn weights from training data.\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        X_train : array, shape = [n_samples, n_features]\n",
    "            Input layer with original features.\n",
    "        y_train : array, shape = [n_samples]\n",
    "            Target class labels.\n",
    "        X_valid : array, shape = [n_samples, n_features]\n",
    "            Sample features for validation during training\n",
    "        y_valid : array, shape = [n_samples]\n",
    "            Sample labels for validation during training\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        self\n",
    "\n",
    "        \"\"\"\n",
    "        n_output = np.unique(y_train).shape[0]  # number of class labels\n",
    "        n_features = X_train.shape[1]\n",
    "\n",
    "        ########################\n",
    "        # Weight initialization\n",
    "        ########################\n",
    "\n",
    "        # weights for input -> hidden\n",
    "        self.b_h = np.zeros(self.n_hidden)\n",
    "        self.w_h = self.random.normal(loc=0.0, scale=0.1,\n",
    "                                      size=(n_features, self.n_hidden))\n",
    "\n",
    "        # weights for hidden -> output\n",
    "        self.b_out = np.zeros(n_output)\n",
    "        self.w_out = self.random.normal(loc=0.0, scale=0.1,\n",
    "                                        size=(self.n_hidden, n_output))\n",
    "\n",
    "        epoch_strlen = len(str(self.epochs))  # for progress formatting\n",
    "        self.eval_ = {'cost': [], 'train_acc': [], 'valid_acc': []}\n",
    "\n",
    "        y_train_enc = self._onehot(y_train, n_output)\n",
    "\n",
    "        # iterate over training epochs\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            # iterate over minibatches\n",
    "            indices = np.arange(X_train.shape[0])\n",
    "\n",
    "            if self.shuffle:\n",
    "                self.random.shuffle(indices)\n",
    "\n",
    "            for start_idx in range(0, indices.shape[0] - self.minibatch_size +\n",
    "                                   1, self.minibatch_size):\n",
    "                batch_idx = indices[start_idx:start_idx + self.minibatch_size]\n",
    "\n",
    "                # forward propagation\n",
    "                z_h, a_h, z_out, a_out = self._forward(X_train[batch_idx])\n",
    "\n",
    "                ##################\n",
    "                # Backpropagation\n",
    "                ##################\n",
    "\n",
    "                # [n_samples, n_classlabels]\n",
    "                sigma_out = a_out - y_train_enc[batch_idx]\n",
    "\n",
    "                # [n_samples, n_hidden]\n",
    "                sigmoid_derivative_h = a_h * (1. - a_h)\n",
    "\n",
    "                # [n_samples, n_classlabels] dot [n_classlabels, n_hidden]\n",
    "                # -> [n_samples, n_hidden]\n",
    "                sigma_h = (np.dot(sigma_out, self.w_out.T) *\n",
    "                           sigmoid_derivative_h)\n",
    "\n",
    "                # [n_features, n_samples] dot [n_samples, n_hidden]\n",
    "                # -> [n_features, n_hidden]\n",
    "                grad_w_h = np.dot(X_train[batch_idx].T, sigma_h)\n",
    "                grad_b_h = np.sum(sigma_h, axis=0)\n",
    "\n",
    "                # [n_hidden, n_samples] dot [n_samples, n_classlabels]\n",
    "                # -> [n_hidden, n_classlabels]\n",
    "                grad_w_out = np.dot(a_h.T, sigma_out)\n",
    "                grad_b_out = np.sum(sigma_out, axis=0)\n",
    "\n",
    "                # Regularization and weight updates\n",
    "                delta_w_h = (grad_w_h + self.l2*self.w_h)\n",
    "                delta_b_h = grad_b_h # bias is not regularized\n",
    "                self.w_h -= self.eta * delta_w_h\n",
    "                self.b_h -= self.eta * delta_b_h\n",
    "\n",
    "                delta_w_out = (grad_w_out + self.l2*self.w_out)\n",
    "                delta_b_out = grad_b_out  # bias is not regularized\n",
    "                self.w_out -= self.eta * delta_w_out\n",
    "                self.b_out -= self.eta * delta_b_out\n",
    "\n",
    "            #############\n",
    "            # Evaluation\n",
    "            #############\n",
    "\n",
    "            # Evaluation after each epoch during training\n",
    "            z_h, a_h, z_out, a_out = self._forward(X_train)\n",
    "            \n",
    "            cost = self._compute_cost(y_enc=y_train_enc,\n",
    "                                      output=a_out)\n",
    "\n",
    "            y_train_pred = self.predict(X_train)\n",
    "            y_valid_pred = self.predict(X_valid)\n",
    "\n",
    "            train_acc = ((np.sum(y_train == y_train_pred)).astype(np.float) /\n",
    "                         X_train.shape[0])\n",
    "            valid_acc = ((np.sum(y_valid == y_valid_pred)).astype(np.float) /\n",
    "                         X_valid.shape[0])\n",
    "\n",
    "            sys.stderr.write('\\r%0*d/%d | Cost: %.2f '\n",
    "                             '| Train/Valid Acc.: %.2f%%/%.2f%% ' %\n",
    "                             (epoch_strlen, i+1, self.epochs, cost,\n",
    "                              train_acc*100, valid_acc*100))\n",
    "            sys.stderr.flush()\n",
    "\n",
    "            self.eval_['cost'].append(cost)\n",
    "            self.eval_['train_acc'].append(train_acc)\n",
    "            self.eval_['valid_acc'].append(valid_acc)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I define the number of epochs, and pre-allocate the vectors that I will store the accuracy data in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "hidden = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.zeros((1,10))\n",
    "numHidden = np.zeros((1,10))\n",
    "i = 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I loop over the training, adding a new layer to the neural network each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100/100 | Cost: 6172.20 | Train/Valid Acc.: 98.92%/98.18%   "
     ]
    }
   ],
   "source": [
    "while (hidden <= 200):\n",
    "    nn = NeuralNetMLP(n_hidden= hidden, \n",
    "                      l2=0.01, \n",
    "                      epochs=n_epochs, \n",
    "                      eta=0.0005,\n",
    "                      minibatch_size=100, \n",
    "                      shuffle=True,\n",
    "                      seed=1)\n",
    "\n",
    "    nn.fit(X_train=X_train[:55000], \n",
    "           y_train=y_train[:55000],\n",
    "           X_valid=X_train[55000:],\n",
    "           y_valid=y_train[55000:])\n",
    "\n",
    "    y_test_pred = nn.predict(X_test)\n",
    "    acc[0,i] = (np.sum(y_test == y_test_pred).astype(np.float) / X_test.shape[0])\n",
    "    numHidden[0,i] = hidden\n",
    "    hidden += 20\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I plot the Test accuracy vs the number of hidden layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAHjhJREFUeJzt3X2UHXWd5/H3J8GA4UEe0jIsIWnAsJBZMeCF466jQRQXfIAQgQUbhBmOGTyiM3JwgRN1NWcziKB4HJnBZgiQsZcHUSSO4wBCAMddIDeQAAkGYyCQwEirxKeWh4Tv/lG/m1Ru+uHeVFffe8nndc49t+pXv6r+VnX3/d7fr6p+pYjAzMxse41rdQBmZtbZnEjMzKwQJxIzMyvEicTMzApxIjEzs0KcSMzMrBAnEjMzK8SJxMzMCnEiMTOzQnZqdQBjYdKkSdHd3d3qMMzMOsrSpUt/FRFdI9XbIRJJd3c31Wq11WGYmXUUSWsbqeeuLTMzK8SJxMzMCnEiMTOzQpxIzMysECcSMzMrxInEzOz1pq8Purth3Ljsva+v1B+3Q1z+a2a2w+jrgzlzYGAgm1+7NpsH6Okp5Ue6RWJm9noyd+6WJFIzMJCVl8SJxMxsNI1xt9I2nnmmufJR4ERiZjZaat1Ka9dCxJZupbFMJlOmNFc+CpxIzMxGSwu6lbYxfz5MnLh12cSJWXlJnEjMzEZLC7qVttHTA729MHUqSNl7b29pJ9rBV22ZmY2eKVOy7qzBysdST0+piaOeWyRmZqOlBd1K7cCJxMxstLSgW6kduGvLzGw0jXG3Ujtwi8TMXh9aff/GDswtEjPrfC0YFsS2KLVFIul4SaskrZZ08SDLp0q6W9Kjku6VNDmVv0fSstzrJUmz0rLrJT2VWzajzH0wsxG0Q0ugHe7f2IGV1iKRNB64CjgOWAcskbQoIlbmql0BLIyIGyQdC1wKnBURi4EZaTt7A6uBO3PrfTYibi0rdjNrULu0BNrh/o0dWJktkqOB1RGxJiJeAW4CTqqrMx24J00vHmQ5wCnAjyJiYJBlZtZK7dISaMGwILZFmYlkf+DZ3Py6VJa3HJidpk8Gdpe0T12d04Eb68rmp+6wKyXtPNgPlzRHUlVStb+/f/v2wMyG1y4tgR30/o120eqrti4EZkp6BJgJrAc21RZK2g94K3BHbp1LgEOBo4C9gYsG23BE9EZEJSIqXV1dJYVvtoNrl5bADnr/RrsoM5GsBw7IzU9OZZtFxHMRMTsijgDmprINuSqnAbdFxKu5dZ6PzMvAdWRdaGbWCu3UEujpgaefhtdey96dRMZMmYlkCTBN0oGSJpB1US3KV5A0SVIthkuABXXbOIO6bq3USkGSgFnA4yXEbmaNcEvAKPGqrYjYKOl8sm6p8cCCiFghaR5QjYhFwDHApZICuB/4ZG19Sd1kLZr76jbdJ6kLELAMOK+sfTCzBuyAd3Lb1hQRrY6hdJVKJarVaqvDMDPrKJKWRkRlpHqtPtluZmYdzonEzMwKcSIxM7NCnEjMzKwQJxIzMyvEicTMzApxIjHrVO0wfLsZfrCVWWdql+HbzXCLxKwztcvw7WY4kZh1pnYZvt0MJxKzztQuw7eb4URi1pnaafh22+E5kZh1Ig/fbm3EicSsWe1y2a0f5GRtwpf/mjXDl92abcMtErNm+LJbs204kZg1w5fdmm3DicSsGb7s1mwbTiRmzfBlt2bbcCIxa4YvuzXbhq/aMmtWT48Th1mOWyRmZlaIE4mZmRVSaiKRdLykVZJWS7p4kOVTJd0t6VFJ90qanMrfI2lZ7vWSpFlp2YGSHkzbvFnShDL3wczMhldaIpE0HrgKOAGYDpwhaXpdtSuAhRFxODAPuBQgIhZHxIyImAEcCwwAd6Z1LgOujIi3AC8C55a1D2ZmNrIyWyRHA6sjYk1EvALcBJxUV2c6cE+aXjzIcoBTgB9FxIAkkSWWW9OyG4BZox65tad2GePKzLZSZiLZH3g2N78uleUtB2an6ZOB3SXtU1fndODGNL0PsCEiNg6zTXs9qo1xtXYtRGwZ48rJxKzlWn2y/UJgpqRHgJnAemBTbaGk/YC3Anc0u2FJcyRVJVX7+/tHK15rFY9xZda2ykwk64EDcvOTU9lmEfFcRMyOiCOAualsQ67KacBtEfFqmv81sKek2v0v22wzt+3eiKhERKWrq6v43lhreYwrs7ZVZiJZAkxLV1lNIOuiWpSvIGmSpFoMlwAL6rZxBlu6tYiIIDuXckoqOhu4vYTYrd14jCuztlVaIknnMc4n65Z6ArglIlZImifpxFTtGGCVpCeBfYHNAxZJ6iZr0dxXt+mLgAskrSY7Z3JtWftgbcRjXJm1LWVf8l/fKpVKVKvVVodhRfX1ZedEnnkma4nMn++hSsxKJGlpRFRGquextqxzeIwrs7bU6qu2zMyswzmRmJlZIU4kZmZWiBOJNcbDk5jZEHyy3UZWG56kdmd5bXgS8MlvM3OLxBrg4UnMbBhOJDYyD09iZsNwIrGReXgSMxuGE4mNzMOTmNkwnEhsZD090NsLU6eClL339vpEu5kBvmrLGuXhScxsCG6RmJlZIU4kZmZWiBOJmZkVMmIikfSgpL+WtMdYBGRmZp2lkRbJ2cBBwDJJ35b03pJjMjOzDjJiIomIn0XERcA04LvAQklPSfq8pD1Lj9DMzNpaQ+dIJE0HvgxcCtwOnAm8AtxTXmhmZtYJRryPRNJDwACwAPhCRPwpLfqppHeWGZyZmbW/Rm5IPDMinhxsQUScOMrxmJlZh2mka+us/LkQSXtJ+lKJMZmZWQdpJJF8KCI21GYi4kXgw+WFZGZmnaSRRDJe0oTajKRdgAnD1Dczsx1II4nkJuAuSWdLOhu4A2jogd2Sjpe0StJqSRcPsnyqpLslPSrpXkmTc8umSLpT0hOSVkrqTuXXp8uPl6XXjEZiMTOzcox4sj0i/k7SY0DtRsSvRMQPR1pP0njgKuA4YB2wRNKiiFiZq3YFsDAibpB0LNnlxWelZQuB+RFxl6TdgNdy6302Im4dKQYzMytfQ8PIR8QPgB80ue2jgdURsQZA0k3ASUA+kUwHLkjTi4Hvp7rTgZ0i4q708//Q5M82M7Mx0shYW0dJekDSbyW9JOllSb9rYNv7A8/m5telsrzlwOw0fTKwu6R9gEOADZK+J+kRSZenFk7N/NQddqWknRuIxczMStLIOZJ/IBtvaw2wO3A+8I1R+vkXAjMlPQLMBNYDm8haSu9Ky48iG+vrnLTOJcChqXxv4KLBNixpjqSqpGp/f/8ohWtmZvUaSSTjImIVWVfTqxFxDfDBBtZbDxyQm5+cyjaLiOciYnZEHAHMTWUbyFovyyJiTURsJOvyOjItfz4yLwPXkXWhbSMieiOiEhGVrq6uBsI1M7Pt0Ugi+WO6/He5pL+T9Clg/EgrAUuAaZIOTOufDizKV5A0SVIthkvIhmGprbunpFoGOJZ0bkXSfuldwCzg8QZiMTOzkjSSSM5J9c4n63aaBpwy0kqpJXE+2eXCTwC3RMQKSfMk1YZWOQZYJelJYF9gflp3E1m31t3pijEB16R1+lLZY8Ak4H83sA9mZlYSRcTQC7MT3NdFxMfGLqTRV6lUolqttjoMM7OOImlpRFRGqjdsiyS1DA6S9IZRi8zMzF5XGrmP5BfATyTdDvyxVhgRo3XllpmZdbBGEskz6TUxvczMzDZrZIiUz49FIGZm1pkaeULiXcA2Z+Qj4v2lRGRmZh2lka6tz+WmdwE+ArxcTjhmZtZpRryPJCIezL3ui4hPA+8eg9gMoK8Purth3Ljsva+hEfzNzMZMI11be+RmxwFvB/YqLSLboq8P5syBgYFsfu3abB6gp6d1cZmZ5TTStbWC7ByJgI3AU8DHywzKkrlztySRmoGBrNyJxMzaRCNXbR0wUh0ryTPPNFduZtYCjTyP5DxJe+bm95I0p9ywDIApU5orNzNrgUYGbTwvDe0OQES8CHyivJBss/nzYWLdPaATJ2blZmZtopFEstWQ8WnYd4+9NRZ6eqC3F6ZOBSl77+31+REzayuNnGy/S9KNwNVp/jzgx+WFZFvp6XHiMLO21kgi+SxZV9Zn0vxdwLdKi8jMzDpKI4nkDcA/RMQ3YXPX1gSyS4HNzGwH18g5ksXArrn5XYF7ygnHzMw6TSOJ5I0R8fvaTJr2cPJmZgY0lkgGJL2tNiNpBvBSeSGZmVknaeQcyWeA2yStJRsm5QDgo6VGZWZmHaORIVIelHQYcFgqWglsKjUqMzPrGI10bRERL0fEMuBNwN8D60uNyszMOkYjY21VJH0tdW39K/AQ8F9Kj8zMzDrCkIlE0jxJq4CvAk8CFeCFiLg2In7VyMYlHS9plaTVki4eZPlUSXdLelTSvZIm55ZNkXSnpCckrZTUncoPlPRg2ubNkiY0t8tmZjaahmuRfBL4JXAlsCAi+hnk2e1DkTQeuAo4AZgOnCFpel21K4CFEXE4MA+4NLdsIXB5RBwGHA28kMovA66MiLcALwLnNhqTmZmNvuESyZ8BXwFOBdZIug54Y7qzvRFHA6sjYk1EvALcBJxUV2c6W25uXFxbnhLOThFxF0BE/CEiBiQJOBa4Na1zAzCrwXjMzKwEQyaFiHg1Iv4lInqAacC/AQ8C6yUtbGDb+wPP5ubXpbK85cDsNH0ysLukfYBDgA2SvifpEUmXpxbOPsCGiNg4zDbNzGwMNXrV1p8i4uaImEV2GfC9o/TzLwRmSnoEmEl2NdgmssuS35WWHwUcBJzTzIYlzZFUlVTt7+8fpXDNzKxeo91Um0XEhohY0EDV9WQ3L9ZMpu6y4Yh4LiJmR8QRwNza9slaGstSt9hG4PvAkcCvgT0l7TTUNnPb7o2ISkRUurq6mthDMzNrRtOJpAlLgGnpKqsJwOnAonwFSZNy51wuARbk1t1TUi0DHAusjIggO5dySio/G7i9xH0wM7MRNHIfyTZ3vw9WVi+1JM4H7gCeAG6JiBXpsuITU7VjgFWSngT2BeandTeRdWvdLekxsqFZrknrXARcIGk12TmTa0eKxczMyqPsS/4wFaSHI+LIkcraWaVSiWq12uowzMw6iqSlEVEZqd6QLQtJbwb2I7vk961krQKAPfAw8mZmlgzXRfVB4K/ITmhfxZZE8nvg8yXHZWZmHWLIRBIR1wHXSTotIm4Zw5jMzKyDNHLV1psl7QEg6WpJD0l6b8lxmZlZh2gkkcyJiN9Jej/ZOZOPkw2dYmZm1lAiqV3W9QGyARaXN7iemZntABpJCMsl/SvwIeBHknajiVGAzczs9a2RZ7b/JfB2spF8ByRNwkO3m5lZMmKLJN1lfhDwiVT0xkbWMzOzHUMjQ6R8E3gPcGYq+iNwdZlBmZlZ52ika+u/RcSRaah3IuI3frytmZnVNNJF9WoaoTcA0oOnXis1KjMz6xhDJpLcCL9XAd8FuiR9Cfh3suemm5mZDdu19RBwZEQslLQUeB/ZeFunRsTjYxKdmZm1veESSW2QRiJiBbCi/HDMzKzTDJdIuiRdMNTCiPhaCfGYmVmHGS6RjAd2I9cyMTMzqzdcInk+IuaNWSRmZtaRhrv81y0RMzMb0XCJxM8cMTOzEQ2ZSCLiN2MZiJmZdSYPvmhmZoU4kZiZWSFOJGZmVkipiUTS8ZJWSVot6eJBlk+VdLekRyXdK2lybtkmScvSa1Gu/HpJT+WWzShzH8zMbHiNDCO/XSSNJxvw8ThgHbBE0qKIWJmrdgXZc+BvkHQscClwVlr2p4gYKkl8NiJuLSt2MzNrXJktkqPJHs+7JiJeAW4CTqqrMx24J00vHmS5mZm1uTITyf7As7n5daksbzkwO02fDOyenncCsIukqqQHJM2qW29+6g67UtLOox65mZk1rNUn2y8EZqanL84E1gOb0rKpEVEBPgp8XdLBqfwS4FDgKGBv4KLBNixpTkpE1f7+/jL3wcxsh1ZmIlkPHJCbn5zKNouI5yJidkQcAcxNZRvS+/r0vga4FzgizT8fmZeB68i60LYREb0RUYmISldX16jumJmZbVFmIlkCTJN0YHrG++nAonwFSZPSY3wha2ksSOV71bqsJE0C3gmsTPP7pXcBswA/ZMvMrIVKu2orIjZKOh+4g2xI+gURsULSPKAaEYuAY4BLJQVwP/DJtPphwLckvUaW7L6cu9qrT1IX2aCSy4DzytoHMzMbmSKi1TGUrlKpRLVabXUYZmYdRdLSdK56WK0+2W5mZh3OicTMzApxIjEzs0KcSMzMrBAnEjMzK8SJxMzMCnEiMTOzQpxIzMysECcSMzMrxInEzMwKcSIxM7NCnEjMzKwQJxIzMyvEicTMzApxIjEzs0KcSMzMrBAnEjMzK8SJxMzMCnEiMTOzQpxIzMysECcSMzMrxInEzMwKcSIxM7NCnEjMzKyQUhOJpOMlrZK0WtLFgyyfKuluSY9KulfS5NyyTZKWpdeiXPmBkh5M27xZ0oQy98HMzIZXWiKRNB64CjgBmA6cIWl6XbUrgIURcTgwD7g0t+xPETEjvU7MlV8GXBkRbwFeBM4tax/MzGxkZbZIjgZWR8SaiHgFuAk4qa7OdOCeNL14kOVbkSTgWODWVHQDMGvUIjYzs6aVmUj2B57Nza9LZXnLgdlp+mRgd0n7pPldJFUlPSCpliz2ATZExMZhtgmApDlp/Wp/f3/RfTEzsyG0+mT7hcBMSY8AM4H1wKa0bGpEVICPAl+XdHAzG46I3oioRESlq6trVIM2M7Mtdipx2+uBA3Lzk1PZZhHxHKlFImk34CMRsSEtW5/e10i6FzgC+C6wp6SdUqtkm22amdnYKrNFsgSYlq6ymgCcDizKV5A0SVIthkuABal8L0k71+oA7wRWRkSQnUs5Ja1zNnB7iftgZmYjKC2RpBbD+cAdwBPALRGxQtI8SbWrsI4BVkl6EtgXmJ/KDwOqkpaTJY4vR8TKtOwi4AJJq8nOmVxb1j6YmdnIlH3Jf32rVCpRrVZbHYaZWUeRtDSdqx5Wq0+2m5lZh3MiMTOzQpxIzMysECcSMzMrxInEzMwKcSIxM7NCnEjMzKwQJxIzMyvEicTMzApxIjEzs0KcSMzMrBAnEjMzK8SJxMzMCnEiGUpfH3R3w7hx2XtfX6sjMjNrS2U+IbFz9fXBnDkwMJDNr12bzQP09LQuLjOzNuQWyWDmzt2SRGoGBrJyMzPbihPJYJ55prlyM7MdmBPJYKZMaa7czGwH5kQymPnzYeLErcsmTszKzcxsK04kg+npgd5emDoVpOy9t9cn2s3MBuGrtobS0+PEYWbWALdIzMysECcSMzMrxInEzMwKcSIxM7NCnEjMzKwQRUSrYyidpH5gbUmbnwT8qqRtj7ZOidVxjr5OidVxjq6icU6NiK6RKu0QiaRMkqoRUWl1HI3olFgd5+jrlFgd5+gaqzjdtWVmZoU4kZiZWSFOJMX1tjqAJnRKrI5z9HVKrI5zdI1JnD5HYmZmhbhFYmZmhTiRNEHSAZIWS1opaYWkv0nlX5S0XtKy9PpAG8T6tKTHUjzVVLa3pLsk/Ty979XiGP9z7pgtk/Q7SX/bLsdT0gJJL0h6PFc26DFU5huSVkt6VNKRLY7zckk/S7HcJmnPVN4t6U+5Y3t1i+Mc8nct6ZJ0PFdJ+u9jFecwsd6ci/NpSctSeSuP6VCfSWP7dxoRfjX4AvYDjkzTuwNPAtOBLwIXtjq+ulifBibVlX0FuDhNXwxc1uo4c7GNB/4DmNouxxN4N3Ak8PhIxxD4APAjQMA7gAdbHOf7gZ3S9GW5OLvz9drgeA76u07/V8uBnYEDgV8A41sZa93yrwJfaINjOtRn0pj+nbpF0oSIeD4iHk7TvweeAPZvbVRNOQm4IU3fAMxqYSz13gv8IiLKunG0aRFxP/CbuuKhjuFJwMLIPADsKWm/VsUZEXdGxMY0+wAweSxiGc4Qx3MoJwE3RcTLEfEUsBo4urTg6gwXqyQBpwE3jlU8QxnmM2lM/06dSLaTpG7gCODBVHR+aiouaHWXURLAnZKWSpqTyvaNiOfT9H8A+7YmtEGdztb/mO12PGuGOob7A8/m6q2jfb5k/BXZt9CaAyU9Iuk+Se9qVVA5g/2u2/l4vgv4ZUT8PFfW8mNa95k0pn+nTiTbQdJuwHeBv42I3wH/CBwMzACeJ2v2ttpfRMSRwAnAJyW9O78wsnZuW1yyJ2kCcCLwnVTUjsdzG+10DIciaS6wEehLRc8DUyLiCOAC4P9I2qNV8dEhv+s6Z7D1l56WH9NBPpM2G4u/UyeSJkl6A9kvrC8ivgcQEb+MiE0R8RpwDWPYBB9KRKxP7y8At5HF9MtaMza9v9C6CLdyAvBwRPwS2vN45gx1DNcDB+TqTU5lLSPpHOBDQE/6MCF1Ff06TS8lO/dwSKtiHOZ33XbHE0DSTsBs4OZaWauP6WCfSYzx36kTSRNS3+i1wBMR8bVceb6P8WTg8fp1x5KkXSXtXpsmO/H6OLAIODtVOxu4vTURbmOrb3jtdjzrDHUMFwEfS1fFvAP4ba5rYcxJOh74n8CJETGQK++SND5NHwRMA9a0Jsphf9eLgNMl7SzpQLI4Hxrr+AbxPuBnEbGuVtDKYzrUZxJj/XfaiisNOvUF/AVZE/FRYFl6fQD4Z+CxVL4I2K/FcR5EdsXLcmAFMDeV7wPcDfwc+DGwdxsc012BXwNvypW1xfEkS27PA6+S9SWfO9QxJLsK5iqyb6OPAZUWx7marC+89nd6dar7kfQ3sQx4GPhwi+Mc8ncNzE3HcxVwQqt/96n8euC8urqtPKZDfSaN6d+p72w3M7NC3LVlZmaFOJGYmVkhTiRmZlaIE4mZmRXiRGJmZoU4kVjLSQpJX83NXyjpi6O07eslnTIa2xrh55wq6QlJi+vKu/MjyKayL0q6ME3Pk/S+QbZ3jKR/GeJnPS1p0ijEfI6kbxbdjpkTibWDl4HZo/HhOJrSXcyNOhf4eES8p5mfERFfiIgfNxdZ56ndsGevT04k1g42kj0S9DP1C+pbFJL+kN6PSQPk3S5pjaQvS+qR9JCy57AcnNvM+yRVJT0p6UNp/fHKntmxJA0Y+Ne57f5E0iJg5SDxnJG2/7iky1LZF8huDLtW0uXN7Hh+/yQdr+wZIg+TDcNRq7OPpDuVPW/in8huKqstOzPt8zJJ38rdYf0HSfMlLZf0gKSGB+iU9I/peK2Q9KVUdqyk7+fqHCfptjT9fkn/T9LDkr6Txn2qtZwuS/tzqqRPK3tuxqOSbmrmOFl7cyKxdnEV0CPpTU2s8zbgPOAw4CzgkIg4Gvgn4FO5et1kYzh9ELha0i5kLYjfRsRRwFHAx9NQHJA9h+JvImKr8ZIk/SeyZ3scSzbI4FGSZkXEPKBKNqbVZweJ82DlHuCVYt5Kiuka4MPA24E/yy3+X8C/R8Sfk42bNiWtcxjwP4B3RsQMYBPQk9bZFXggIt4G3A98fIhjOJi5EVEBDgdmSjocWAwcKqkr1flLYEFqRX4OeF9kg4RWyQYurPl1RBwZETeRPRfjiIg4fLBjYJ3LicTaQmQjli4EPt3Eaksiex7Dy2RDPtyZyh8jSx41t0TEa5EN+70GOJRs/LGPpQ/2B8mGlJiW6j8U2TMw6h0F3BsR/ZE966OP7AFII/lFRMyovYDBnqB3KPBURPw8suEmvp1b9u7afET8EHgxlb+XLOksSfvxXrLhcQBeAWrnWJay9fEYyWmpFfEI8OfA9BTTPwNnKnva4n8lG5r+HWQPUvppiuFssoeT1dycm34U6JN0Jlkr1F4nmukDNivb18nGKrouV7aR9IVH0jhgQm7Zy7np13Lzr7H133b9OEBB1j30qYi4I79A0jHAH7cv/DEn4IaIuGSQZa/GlvGPNtHg/3pqlV0IHBURL0q6HtglLb4O+AHwEvCdiNiYBg28KyLOGGKT+WP5QbKk+GFgrqS3xpaHb1kHc4vE2kZE/Aa4hazbqeZpsm/dkD2z5A3bselTJY1L500OIhsE8A7gE8qG4EbSIcpGSh7OQ2RdPZPSuYgzgPu2I57B/Azozp3byX8w3w98NMV5AlB7+NPdwCmS3pyW7S0p3xrYHnuQffj/Np1XOaG2ICKeA54j68qqJfsHgHdKekuKYVdJ2wyhnr4EHBARi4GLgDcBuxWM1dqEWyTWbr4KnJ+bvwa4XdJy4N/YvtbCM2RJYA+ykVtfSietu4GH07fqfkZ49HBEPC/pYrLzBQJ+GBGjMhR/imkO8ENJA8BPyJ7BDfAl4EZJK4D/m/aHiFgp6XNkT8IcRzZS7SeBZh5XfI6k/H6/g6xL62dkowf/tK5+H9AVEU+kGPqVPffkRkk7pzqfI3t2eN544NvpHJiAb0TEhibitDbm0X/NrGHK7jt5JCKubXUs1j6cSMysIZKWkrUIj0sXOJgBTiRmZlaQT7abmVkhTiRmZlaIE4mZmRXiRGJmZoU4kZiZWSFOJGZmVsj/B8ndQavA7aKjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f84932da9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(numHidden, acc, 'ro')\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.xlabel(\"Number of Hidden Layers\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Using tensorflow to create a two layer neural network to classify mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am importing mnist from tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-30-80aa5e208d67>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/jack/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/jack/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/jack/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/jack/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am doing the test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist.train.images\n",
    "X_test = mnist.test.images\n",
    "y_train = mnist.train.labels.astype(\"int\")\n",
    "y_test = mnist.test.labels.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am describing the shape of the neural network, there are 784 inputs because mnist is a 28 * 28 pixel image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 784\n",
    "n_hidden1 = 200\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholder nodes represent the training data and targets. The shapes of X and Y are only partialy defined because we do not know the batch size yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape = (None, n_inputs), name = \"X\")\n",
    "y = tf.placeholder(tf.int64, shape = (None), name = \"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define each layer of the the network, notice that tanh is used for the activation function of the two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name = \"hidden1\", \n",
    "                             activation = tf.nn.tanh)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name = \"hidden2\", \n",
    "                             activation = tf.nn.tanh)\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name = \"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross entropy is used to define the cost function of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y,\n",
    "                                                             logits = logits)\n",
    "    loss = tf.reduce_mean(xentropy, name = \"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A gradient descent optimizer adjusts the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer =  tf.train.GradientDescentOptimizer(learningRate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define accuracy as the measure we will use to evaluate the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"evaluation\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node to initalize all the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define number of epochs, batch size and preallocate space for train and test accuracy vectors and the vector that keeps track of the epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 50\n",
    "trainAcc = np.zeros((1,100))\n",
    "testAcc = np.zeros((1,100))\n",
    "epochVec = np.zeros((1,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I train the network, filling up each of the accuracy vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.8799999952316284 Test accuracy: 0.8966000080108643\n",
      "5 Train accuracy: 0.9200000166893005 Test accuracy: 0.9337000250816345\n",
      "10 Train accuracy: 1.0 Test accuracy: 0.9477999806404114\n",
      "15 Train accuracy: 0.9200000166893005 Test accuracy: 0.9557999968528748\n",
      "20 Train accuracy: 0.9800000190734863 Test accuracy: 0.9613000154495239\n",
      "25 Train accuracy: 0.9800000190734863 Test accuracy: 0.9649999737739563\n",
      "30 Train accuracy: 0.9800000190734863 Test accuracy: 0.9670000076293945\n",
      "35 Train accuracy: 0.9800000190734863 Test accuracy: 0.9689000248908997\n",
      "40 Train accuracy: 1.0 Test accuracy: 0.9702000021934509\n",
      "45 Train accuracy: 1.0 Test accuracy: 0.972100019454956\n",
      "50 Train accuracy: 0.9800000190734863 Test accuracy: 0.9728000164031982\n",
      "55 Train accuracy: 0.9800000190734863 Test accuracy: 0.9739999771118164\n",
      "60 Train accuracy: 1.0 Test accuracy: 0.9749000072479248\n",
      "65 Train accuracy: 1.0 Test accuracy: 0.975600004196167\n",
      "70 Train accuracy: 1.0 Test accuracy: 0.9763000011444092\n",
      "75 Train accuracy: 1.0 Test accuracy: 0.9760000109672546\n",
      "80 Train accuracy: 1.0 Test accuracy: 0.9764000177383423\n",
      "85 Train accuracy: 1.0 Test accuracy: 0.9768999814987183\n",
      "90 Train accuracy: 1.0 Test accuracy: 0.9768999814987183\n",
      "95 Train accuracy: 1.0 Test accuracy: 0.9771999716758728\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict= {X: X_batch, y: y_batch})\n",
    "        trainAcc[0,epoch] = accuracy.eval(feed_dict= {X: X_batch, \n",
    "                                                      y: y_batch})\n",
    "        testAcc[0, epoch] = accuracy.eval(feed_dict={X:mnist.test.images,\n",
    "                                                    y: mnist.test.labels})\n",
    "        epochVec[0, epoch] = epoch;\n",
    "        \n",
    "        if(epoch%5 == 0):\n",
    "            print(epoch, \"Train accuracy:\", trainAcc[0,epoch],\n",
    "                 \"Test accuracy:\", testAcc[0,epoch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8479d34128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochVec, trainAcc, 'ro')\n",
    "plt.plot(epochVec, testAcc, 'g^')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEGEND: Red dots are the training accuracy, Green triangles are the test accuracy\n",
    "\n",
    "This is the plot of train and test accuracy vs the epoch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
